<meta charset="utf-8"/>
<h3>
 Question 1
</h3>
<co-content>
 <p>
  <strong>
   True or False.
  </strong>
  Because of the knowledge cut-off, an LLM cannot answer questions about today’s news. But with RAG to supply it articles from the news, it would be able to.
 </p>
</co-content>
<form>
 <label>
  <input name="0" type="radio"/>
  <co-content>
   <span>
    True
   </span>
  </co-content>
  <br/>
 </label>
 <label>
  <input name="0" type="radio"/>
  <co-content>
   <span>
    False
   </span>
  </co-content>
  <br/>
 </label>
</form>
<hr/>
<h3>
 Question 2
</h3>
<co-content>
 <p>
  You want to build an application to answer questions based on information found in your emails. Which of the following is the most appropriate technique?
 </p>
</co-content>
<form>
 <label>
  <input name="1" type="radio"/>
  <co-content>
   <span>
    RAG, where the LLM is provided additional context based on retrieving emails relevant to your question.
   </span>
  </co-content>
  <br/>
 </label>
 <label>
  <input name="1" type="radio"/>
  <co-content>
   <span>
    Pretraining an LLM on your emails.
   </span>
  </co-content>
  <br/>
 </label>
 <label>
  <input name="1" type="radio"/>
  <co-content>
   <span>
    Prompting (without RAG), where we iteratively refine the prompt until the LLM gets the answers right.
   </span>
  </co-content>
  <br/>
 </label>
 <label>
  <input name="1" type="radio"/>
  <co-content>
   <span>
    Fine-tuning an LLM on your emails, whereby we take a pre-trained LLM and further train it on your emails.
   </span>
  </co-content>
  <br/>
 </label>
</form>
<hr/>
<h3>
 Question 3
</h3>
<co-content>
 <p>
  What does the idea of using an LLM as a reasoning engine refer to?
 </p>
</co-content>
<form>
 <label>
  <input name="2" type="radio"/>
  <co-content>
   <span>
    This refers to the idea of using an LLM not as a source of information, but to process information (wherein we provide it the context it needs, through techniques like RAG).
   </span>
  </co-content>
  <br/>
 </label>
 <label>
  <input name="2" type="radio"/>
  <co-content>
   <span>
    The idea of using an LLM to play games (like chess) that require complex reasoning, but having its output moves in the game.
   </span>
  </co-content>
  <br/>
 </label>
 <label>
  <input name="2" type="radio"/>
  <co-content>
   <span>
    Reasoning engine is another term for RAG.
   </span>
  </co-content>
  <br/>
 </label>
 <label>
  <input name="2" type="radio"/>
  <co-content>
   <span>
    This refers to pretraining an LLM on a lot of text so that it acquires general reasoning capabilities.
   </span>
  </co-content>
  <br/>
 </label>
</form>
<hr/>
<h3>
 Question 4
</h3>
<co-content>
 <p>
  <strong>
   True or False.
  </strong>
  By making trusted sources of information available to an LLM via RAG, we can reduce the risk of hallucination.
 </p>
</co-content>
<form>
 <label>
  <input name="3" type="radio"/>
  <co-content>
   <span>
    False, because the LLM has learned from a lot of text from the internet (perhaps &gt;100 billion words) to hallucinate, so adding one more short piece of text to the prompt as in RAG won’t make any meaningful difference.
   </span>
  </co-content>
  <br/>
 </label>
 <label>
  <input name="3" type="radio"/>
  <co-content>
   <span>
    True, because RAG allows the LLM to reason through accurate information retrieved from a trusted source to arrive at the correct answer.
   </span>
  </co-content>
  <br/>
 </label>
 <label>
  <input name="3" type="radio"/>
  <co-content>
   <span>
    False, because giving the LLM more information only confuses the LLM more and causes it to be more likely to hallucinate.
   </span>
  </co-content>
  <br/>
 </label>
 <label>
  <input name="3" type="radio"/>
  <co-content>
   <span>
    True, because the LLM is now restricted to outputting paragraphs of text exactly as written in the provided document, which we trust.
   </span>
  </co-content>
  <br/>
 </label>
</form>
<hr/>
<h3>
 Question 5
</h3>
<co-content>
 <p>
  An ecommerce company is building a software application to route emails to the right department (Apparel, Electronics, Home Appliances, etc.) It wants to do so with a small, 1 billion parameter model, and needs high accuracy. Which of these is an appropriate technique?
 </p>
</co-content>
<form>
 <label>
  <input name="4" type="radio"/>
  <co-content>
   <span>
    Pretrain a 1 billion parameter model on around 1,000 examples of emails and the appropriate department.
   </span>
  </co-content>
  <br/>
 </label>
 <label>
  <input name="4" type="radio"/>
  <co-content>
   <span>
    Fine-tune a 1 billion parameter model on around 1 billion examples of emails and the appropriate department.
   </span>
  </co-content>
  <br/>
 </label>
 <label>
  <input name="4" type="radio"/>
  <co-content>
   <span>
    Fine-tune a 1 billion parameter model on around 1,000 examples of emails and the appropriate department.
   </span>
  </co-content>
  <br/>
 </label>
 <label>
  <input name="4" type="radio"/>
  <co-content>
   <span>
    Pretrain a 1 billion parameter model on around 1 billion examples of emails and the appropriate department.
   </span>
  </co-content>
  <br/>
 </label>
</form>
<hr/>
<style>
 body {
    padding: 50px 85px 50px 85px;
}

table th, table td {
    border: 1px solid #e0e0e0;
    padding: 5px 20px;
    text-align: left;
}
input {
    margin: 10px;
}
}
th {
    font-weight: bold;
}
td, th {
    display: table-cell;
    vertical-align: inherit;
}
img {
    height: auto;
    max-width: 100%;
}
pre {
    display: block;
    margin: 20px;
    background: #424242;
    color: #fff;
    font-size: 13px;
    white-space: pre-wrap;
    padding: 9.5px;
    margin: 0 0 10px;
    border: 1px solid #ccc;
}
</style>
<script async="" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript">
</script>
<script type="text/x-mathjax-config">
 MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$$','$$'], ['$','$'] ],
      displayMath: [ ["\\[","\\]"] ],
      processEscapes: true
    }
  });
</script>
